
#  ********************************************   数据增强      ***********************
    # from collections import Counter
    # import random
    # import jieba    

    # depart_counts = Counter(data[3].item() for data in train_data)
    # min_count = min(depart_counts.values())
    # max_count = max(depart_counts.values())

    # threshold = max_count * 0.1  # 长尾类别阈值
    # long_tail_classes = [key for key, count in depart_counts.items() if count < threshold]
    # target_count = int(max_count * 0.15)  # 增广上限（例：主流类别的一半）

    # def augment_text(text):
    #     # 增广方法（随机删除、重复汉字，分词拆解重组）
    #     if random.random() < 0.25:
    #         num_del = random.randint(1, len(text) // 4 + 1)
    #         indices = random.sample(range(len(text)), num_del)
    #         text = ''.join([c for i, c in enumerate(text) if i not in indices])

    #     if random.random() < 0.25:
    #         indices = random.sample(range(len(text)), random.randint(1, len(text) // 4 + 1))
    #         for idx in indices:
    #             text = text[:idx] + text[idx] + text[idx:]

    #     if random.random() < 0.25:
    #         words = list(jieba.cut(text))
    #         random.shuffle(words)
    #         text = ''.join(words)
    #     return text

    # def apply_mask(vs_tensor, mask_ratio=0.1):
    #     """
    #     对VS数据进行遮挡操作，mask_ratio表示遮挡的比例。
    #     这里简单通过随机选择一定比例的元素置为零来进行遮挡。
    #     """
    #     # 创建一个mask，表示哪些元素应该被遮挡
    #     mask = torch.rand(vs_tensor.size()) < mask_ratio  # 随机生成mask
    #     masked_vs = vs_tensor.clone()  # 克隆一个副本避免原数据改变
    #     masked_vs[mask] = 0  # 将被mask的元素置为0
    #     return masked_vs

    # # 上采样长尾类别
    # augmented_data = []
    # for data in tqdm(train_data):
    #     if data[3].item() in long_tail_classes:
    #         current_count = sum(1 for d in augmented_data if d[3] == data[3])
    #         if current_count < target_count:  # 增广数据不能超过目标数量
    #             vs_masked = apply_mask(data[0], mask_ratio=0.1) 
    #             cc_augmented = augment_text(data[1])
    #             new_data = (vs_masked, cc_augmented, data[2], data[3], data[4])
    #             augmented_data.append(new_data)
    # final_data = train_data + augmented_data

    # random.shuffle(final_data)
#  *******************************************************************